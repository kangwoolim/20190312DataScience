{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re # 정규표현식을 사용해 텍스트 데이터를 정제한다.\n",
    "import random # 랜덤 숫자를 생성하기 위해\n",
    "from math import exp, log # 지수함수와 로그함수를 사용하기 위해\n",
    "from datetime import datetime # 시간 계산\n",
    "from operator import itemgetter #키가 아닌 값으로 max, min 값을 구할 때 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(s):\n",
    "    \"\"\"\n",
    "        Returns a cleand, lowercased string\n",
    "        텍스트 데이터를 정제하고 소문자로 변환해 준다.\n",
    "    \"\"\"\n",
    "    \n",
    "    return \" \".join(re.findall(r'\\w+', s , flags = re.UNICODE)).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_tsv(loc_dataset,opts):\n",
    "    \"\"\"\n",
    "    Running through data in an online manner\n",
    "    Parses a tsv file for this competition \n",
    "    and yields label, identifier and features\n",
    "    output:\n",
    "            label: int, The label / target (set to \"1\" if test set)\n",
    "            id: string, the sample identifier\n",
    "            features: list of tuples, \n",
    "                in the form [(hashed_feature_index,feature_value)]\n",
    "\n",
    "    온라인 학습 방법을 통해 데이터를 실행한다.\n",
    "    tsv파일을 통해 레이블, identifier, 피처(특성)를 파싱한다.\n",
    "    결과물:\n",
    "        label : int, 레이블 / 대상 (테스트 집합 인 경우 \"1\"로 설정)\n",
    "        id : 문자열, 샘플 식별자\n",
    "        features : [(hashed_feature_index, feature_value)] \n",
    "                형식의 튜플 목록\n",
    "    \"\"\"\n",
    "    for e, line in enumerate(open(loc_dataset,\"rb\")):\n",
    "        if e > 0:\n",
    "            r = line.decode('utf-8').strip().split(\"\\t\")\n",
    "            id = r[0]\n",
    "\n",
    "            if opts[\"clean\"]:\n",
    "                try:\n",
    "                    r[2] = clean(r[2])\n",
    "                except:\n",
    "                    r[1] = clean(r[1])\n",
    "\n",
    "            # opts[\"D\"] = 2 ** 25 = 33554432\n",
    "            # Vowpal Wabbit의 해싱트릭을 사용한다.\n",
    "            # 해싱트릭은 큰 규모의 feature공간을 \n",
    "            # 고정크기의 표현을 사용해 저장할 수 있게 한다.\n",
    "            if len(r) == 3: # train set\n",
    "                features = [(hash(f)%opts[\"D\"],1) for f in r[2].split()]\n",
    "                label = int(r[1])\n",
    "            else: #test set\n",
    "                features = [(hash(f)%opts[\"D\"],1) for f in r[1].split()]\n",
    "                label = 1\n",
    "\n",
    "            # bigram을 사용하면 해당 피처[i]와 다음피처[i+1]를 함께 해싱한다.\n",
    "            if opts[\"2grams\"]:\n",
    "                for i in range(len(features)-1):\n",
    "                    features.append(\n",
    "                        (hash(str(features[i][0])+str(features[i+1][0]))%opts[\"D\"],1))\n",
    "            yield label, id, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product(features,weights):\n",
    "    \"\"\"\n",
    "    Calculate dot product from features and weights\n",
    "    input:\n",
    "            features: A list of tuples [(feature_index,feature_value)]\n",
    "            weights: the hashing trick weights filter, \n",
    "            note: length is max(feature_index)\n",
    "    output:\n",
    "            dotp: the dot product\n",
    "    피처(특성)과 가중치로부터 내적을 구한다.\n",
    "    \"\"\"\n",
    "    dotp = 0\n",
    "    for f in features:\n",
    "        dotp += weights[f[0]] * f[1]\n",
    "    return dotp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tron(loc_dataset,opts):\n",
    "    start = datetime.now()\n",
    "    print(\"\\nPass\\t\\tErrors\\t\\tAverage\\t\\tNr. Samples\\tSince Start\")\n",
    "\n",
    "    # 가중치 초기화\n",
    "    if opts[\"random_init\"]:\n",
    "        random.seed(3003)\n",
    "        weights = [random.random()] * opts[\"D\"]\n",
    "    else:\n",
    "        weights = [0.] * opts[\"D\"]\n",
    "\n",
    "    # Running training passes\n",
    "    # 학습 실행\n",
    "    for pass_nr in range(opts[\"n_passes\"]):\n",
    "        error_counter = 0\n",
    "        for e, (label, id, features) in enumerate( \\\n",
    "            get_data_tsv(loc_dataset,opts) ):\n",
    "\n",
    "            # 퍼셉트론은 지도학습 분류기의 일종이다. \n",
    "            # 이전 값에 대한 학습으로 예측을 한다. \n",
    "            # 내적(dotproduct) 값이 임계 값보다 높거나 낮은지에 따라 \n",
    "            # 초과하면 \"1\"을 예측하고 미만이면 \"0\"을 예측한다.\n",
    "            dp = dot_product(features, weights) > 0.5\n",
    "\n",
    "            # 다음 perceptron은 샘플의 레이블을 본다. \n",
    "            # 실제 레이블 데이터에서 위 퍼셉트론으로 구한 dp값을 빼준다.\n",
    "            # 예측이 정확하다면, error 값은 \"0\"이며, 가중치만 남겨 둔다. \n",
    "            # 예측이 틀린 경우 error 값은 \"1\" 또는 \"-1\"이고 다음과 같이 가중치를 업데이트 한다.\n",
    "            # weights[feature_index] += learning_rate * error * feature_value\n",
    "            error = label - dp \n",
    "\n",
    "            # 예측이 틀린 경우 퍼셉트론은 다음과 같이 가중치를 업데이트한다.\n",
    "            if error != 0:\n",
    "                error_counter += 1\n",
    "                # Updating the weights\n",
    "                for index, value in features:\n",
    "                    weights[index] += opts[\"learning_rate\"] * error * log(1.+value)\n",
    "\n",
    "        #Reporting stuff\n",
    "        print(\"%s\\t\\t%s\\t\\t%s\\t\\t%s\\t\\t%s\" % ( \\\n",
    "            pass_nr+1,\n",
    "            error_counter,\n",
    "            round(1 - error_counter /float(e+1),5),\n",
    "            e+1,datetime.now()-start))\n",
    "\n",
    "        #Oh heh, we have overfit :)\n",
    "        if error_counter == 0 or error_counter < opts[\"errors_satisfied\"]:\n",
    "            print(\"%s errors found during training, halting\"%error_counter)\n",
    "            break\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_tron(loc_dataset,weights,opts):\n",
    "    \"\"\"\n",
    "        output:\n",
    "                preds: list, a list with\n",
    "                [id,prediction,dotproduct,0-1normalized dotproduct]\n",
    "    \"\"\"\n",
    "    start = datetime.now()\n",
    "    print(\"\\nTesting online\\nErrors\\t\\tAverage\\t\\tNr. Samples\\tSince Start\")\n",
    "    preds = []\n",
    "    error_counter = 0\n",
    "    for e, (label, id, features) in enumerate( \\\n",
    "        get_data_tsv(loc_dataset,opts) ):\n",
    "\n",
    "        dotp = dot_product(features, weights)\n",
    "        # 내적이 0.5보다 크다면 긍정으로 예측한다.\n",
    "        dp = dotp > 0.5\n",
    "        if dp > 0.5: # we predict positive class\n",
    "            preds.append( [id, 1, dotp ] )\n",
    "        else:\n",
    "            preds.append( [id, 0, dotp ] )\n",
    "\n",
    "        # get_data_tsv에서 테스트 데이터의 레이블을 1로 초기화 해주었음\n",
    "        if label - dp != 0:\n",
    "            error_counter += 1\n",
    "\n",
    "    print(\"%s\\t\\t%s\\t\\t%s\\t\\t%s\" % (\n",
    "        error_counter,\n",
    "        round(1 - error_counter /float(e+1),5),\n",
    "        e+1,\n",
    "        datetime.now()-start))\n",
    "\n",
    "    # normalizing dotproducts between 0 and 1 \n",
    "    # 내적을 구해 0과 1로 일반화 한다.\n",
    "    # TODO: proper probability (bounded sigmoid?), \n",
    "    # online normalization\n",
    "    max_dotp = max(preds,key=itemgetter(2))[2]\n",
    "    min_dotp = min(preds,key=itemgetter(2))[2]\n",
    "    for p in preds:\n",
    "        # appending normalized to predictions\n",
    "        # 정규화 된 값을 마지막에 추가해 준다.\n",
    "        # (피처와 가중치에 대한 내적값 - 최소 내적값) / 최대 내적값 - 최소 내적값\n",
    "        # 이 값이 캐글에서 0.95의 AUC를 얻을 수 있는 값이다.\n",
    "        p.append((p[2]-min_dotp)/float(max_dotp-min_dotp)) \n",
    "\n",
    "    #Reporting stuff\n",
    "    print(\"Done testing in %s\"%str(datetime.now()-start))\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pass\t\tErrors\t\tAverage\t\tNr. Samples\tSince Start\n",
      "1\t\t5699\t\t0.77204\t\t25000\t\t0:00:12.695719\n",
      "2\t\t3174\t\t0.87304\t\t25000\t\t0:00:24.730266\n",
      "3\t\t2240\t\t0.9104\t\t25000\t\t0:00:36.273509\n",
      "4\t\t1622\t\t0.93512\t\t25000\t\t0:00:47.877083\n",
      "5\t\t1266\t\t0.94936\t\t25000\t\t0:00:59.305102\n",
      "6\t\t1015\t\t0.9594\t\t25000\t\t0:01:10.669093\n",
      "7\t\t831\t\t0.96676\t\t25000\t\t0:01:21.995062\n",
      "8\t\t639\t\t0.97444\t\t25000\t\t0:01:33.375016\n",
      "9\t\t495\t\t0.9802\t\t25000\t\t0:01:44.727495\n",
      "10\t\t455\t\t0.9818\t\t25000\t\t0:01:56.065084\n",
      "11\t\t360\t\t0.9856\t\t25000\t\t0:02:07.403034\n",
      "12\t\t262\t\t0.98952\t\t25000\t\t0:02:18.889514\n",
      "13\t\t258\t\t0.98968\t\t25000\t\t0:02:30.199061\n",
      "14\t\t236\t\t0.99056\t\t25000\t\t0:02:41.564341\n",
      "15\t\t254\t\t0.98984\t\t25000\t\t0:02:53.024039\n",
      "16\t\t191\t\t0.99236\t\t25000\t\t0:03:04.342697\n",
      "17\t\t179\t\t0.99284\t\t25000\t\t0:03:15.635016\n",
      "18\t\t141\t\t0.99436\t\t25000\t\t0:03:27.049102\n",
      "19\t\t104\t\t0.99584\t\t25000\t\t0:03:38.381489\n",
      "20\t\t71\t\t0.99716\t\t25000\t\t0:03:49.608233\n",
      "21\t\t112\t\t0.99552\t\t25000\t\t0:04:00.981017\n",
      "22\t\t97\t\t0.99612\t\t25000\t\t0:04:12.520004\n",
      "23\t\t106\t\t0.99576\t\t25000\t\t0:04:23.809499\n",
      "24\t\t68\t\t0.99728\t\t25000\t\t0:04:35.215055\n",
      "25\t\t43\t\t0.99828\t\t25000\t\t0:04:46.500005\n",
      "26\t\t49\t\t0.99804\t\t25000\t\t0:04:58.159292\n",
      "27\t\t60\t\t0.9976\t\t25000\t\t0:05:09.859962\n",
      "28\t\t11\t\t0.99956\t\t25000\t\t0:05:21.320352\n",
      "29\t\t42\t\t0.99832\t\t25000\t\t0:05:32.553865\n",
      "30\t\t16\t\t0.99936\t\t25000\t\t0:05:44.279729\n",
      "31\t\t42\t\t0.99832\t\t25000\t\t0:05:55.670043\n",
      "32\t\t22\t\t0.99912\t\t25000\t\t0:06:07.020973\n",
      "33\t\t27\t\t0.99892\t\t25000\t\t0:06:18.356908\n",
      "34\t\t51\t\t0.99796\t\t25000\t\t0:06:29.823983\n",
      "35\t\t15\t\t0.9994\t\t25000\t\t0:06:41.211076\n",
      "36\t\t14\t\t0.99944\t\t25000\t\t0:06:52.658993\n",
      "37\t\t4\t\t0.99984\t\t25000\t\t0:07:04.034182\n",
      "38\t\t25\t\t0.999\t\t25000\t\t0:07:15.278925\n",
      "39\t\t14\t\t0.99944\t\t25000\t\t0:07:26.629063\n",
      "40\t\t28\t\t0.99888\t\t25000\t\t0:07:38.074691\n",
      "41\t\t7\t\t0.99972\t\t25000\t\t0:07:49.327851\n",
      "42\t\t5\t\t0.9998\t\t25000\t\t0:08:00.573905\n",
      "43\t\t9\t\t0.99964\t\t25000\t\t0:08:12.013910\n",
      "44\t\t20\t\t0.9992\t\t25000\t\t0:08:23.257894\n",
      "45\t\t0\t\t1.0\t\t25000\t\t0:08:34.501183\n",
      "0 errors found during training, halting\n",
      "Wall time: 8min 34s\n"
     ]
    }
   ],
   "source": [
    "#Setting options\n",
    "opts = {}\n",
    "opts[\"D\"] = 2 ** 25\n",
    "opts[\"learning_rate\"] = 0.1\n",
    "opts[\"n_passes\"] = 80 # Maximum number of passes to run before halting\n",
    "opts[\"errors_satisfied\"] = 0 # Halt when training errors < errors_satisfied\n",
    "opts[\"random_init\"] = False # set random weights, else set all 0\n",
    "opts[\"clean\"] = True # clean the text a little\n",
    "opts[\"2grams\"] = True # add 2grams\n",
    "\n",
    "#training and saving model into weights\n",
    "%time weights = train_tron(\"data/labeledTrainData.tsv\",opts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "presult = pd.DataFrame(preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
